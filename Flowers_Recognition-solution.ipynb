{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXgJ6uT1NydQ"
   },
   "source": [
    "Assignment: Flowers Recognition <br>\n",
    "Dataset Description:<br>\n",
    "\n",
    "This dataset contains 4242 images of flowers.<br>\n",
    "The data collection is based on the data flicr, google images, yandex images.<br>\n",
    "You can use this datastet to recognize plants from the photo.<br>\n",
    "\n",
    "Attribute Information:<br>\n",
    "The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.<br>\n",
    "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. <br>\n",
    "<b>Also explore how to resize images in tensorflow and then resize all the images to a same size. </b> <br>\n",
    "This is a Multiclass Classification Problem.<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7vy-ktuOKJH"
   },
   "source": [
    "WORKFLOW : <br>\n",
    "Load Data <br>\n",
    "Split into 60 and 40 ratio.<br>\n",
    "Encode labels.<br>\n",
    "Create Model<br>\n",
    "Compilation Step (Note : Its a Multiclass Classification problem , select loss , metrics according to it)<br>\n",
    "Train the Model.<br>\n",
    "If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .<br>\n",
    "Prediction should be > 85%<br>\n",
    "Evaluation Step<br>\n",
    "Prediction<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri3Bg5qfPRic"
   },
   "source": [
    "Data : <br>\n",
    "https://drive.google.com/file/d/1-OX6wn5gA-bJpjPNfSyaYQLz-A-AB_uj/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hTtg3WuGTA1o"
   },
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3028 images belonging to 5 classes.\n",
      "Found 1295 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#Generating Data (Train, Test & Validation)\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        validation_split=0.3,\n",
    "        horizontal_flip=True,\n",
    "        )\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\Bilal Imran Butt\\Desktop\\PIAIC\\dl_assignments\\flowers',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset = 'training'\n",
    "        )\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\Bilal Imran Butt\\Desktop\\PIAIC\\dl_assignments\\flowers',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models with Conv2D and Maxpooling\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiing model and assigning relevant metrics\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\bilal imran butt\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (8.2.0)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 110s 11s/step - loss: 1.0868 - accuracy: 0.6125 - val_loss: 1.4087 - val_accuracy: 0.5260\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 108s 11s/step - loss: 1.0479 - accuracy: 0.5781 - val_loss: 1.3428 - val_accuracy: 0.4542\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 109s 11s/step - loss: 1.1251 - accuracy: 0.5688 - val_loss: 1.0431 - val_accuracy: 0.6031\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 109s 11s/step - loss: 1.0140 - accuracy: 0.6187 - val_loss: 0.9544 - val_accuracy: 0.6333\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 108s 11s/step - loss: 1.0591 - accuracy: 0.5875 - val_loss: 1.0144 - val_accuracy: 0.5990\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 109s 11s/step - loss: 1.0167 - accuracy: 0.6031 - val_loss: 1.0099 - val_accuracy: 0.6135\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 110s 11s/step - loss: 0.9131 - accuracy: 0.6656 - val_loss: 1.1621 - val_accuracy: 0.5281\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 107s 11s/step - loss: 0.9216 - accuracy: 0.6594 - val_loss: 1.0149 - val_accuracy: 0.6000\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 108s 11s/step - loss: 1.0065 - accuracy: 0.6062 - val_loss: 1.0173 - val_accuracy: 0.6208\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 109s 11s/step - loss: 1.0324 - accuracy: 0.5938 - val_loss: 0.9689 - val_accuracy: 0.6281\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 109s 11s/step - loss: 1.0038 - accuracy: 0.6187 - val_loss: 0.9963 - val_accuracy: 0.6104\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.9992 - accuracy: 0.6281 - val_loss: 1.1036 - val_accuracy: 0.5625\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 110s 12s/step - loss: 1.0226 - accuracy: 0.6438 - val_loss: 0.9233 - val_accuracy: 0.6344\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.9937 - accuracy: 0.6375 - val_loss: 0.8849 - val_accuracy: 0.6458\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.8903 - accuracy: 0.6719 - val_loss: 1.0572 - val_accuracy: 0.5906\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 108s 11s/step - loss: 0.9191 - accuracy: 0.6562 - val_loss: 0.9577 - val_accuracy: 0.6302\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 109s 11s/step - loss: 1.0074 - accuracy: 0.6281 - val_loss: 0.9846 - val_accuracy: 0.6104\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 109s 11s/step - loss: 0.9494 - accuracy: 0.6187 - val_loss: 1.1706 - val_accuracy: 0.5458\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 115s 12s/step - loss: 0.8669 - accuracy: 0.6461 - val_loss: 0.9628 - val_accuracy: 0.6344\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 123s 13s/step - loss: 0.9460 - accuracy: 0.6281 - val_loss: 1.0345 - val_accuracy: 0.5729\n"
     ]
    }
   ],
   "source": [
    "#Applying .fit operation to start execution using built model\n",
    "with tf.device('/device:GPU:0'):\n",
    "  model.fit(\n",
    "          train_generator,\n",
    "          steps_per_epoch=10,\n",
    "          epochs=20,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 70s 2s/step - loss: 1.0156 - accuracy: 0.5714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.015568733215332, 0.5714285969734192]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying .evaluate method to validate the partially splitted validation data-set\n",
    "model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Flowers Recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
